{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input , train_target = bci.load(root = './data_bci')\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input , train_target = bci.load(root = './data_bci', one_khz = True)\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False, one_khz = True)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  30.8000   33.1000   37.9000  ...    76.9000   75.9000   72.3000\n",
       " -22.6000  -19.2000  -11.8000  ...    26.8000   22.9000   16.4000\n",
       "  11.2000   16.7000   26.4000  ...    64.1000   62.0000   55.9000\n",
       "             ...                â‹±                ...             \n",
       "   0.5000    0.5000    0.4000  ...    45.1000   46.2000   46.6000\n",
       "  11.0000   10.6000    9.8000  ...    41.7000   41.5000   40.9000\n",
       "  -9.9000  -10.0000  -10.3000  ...    32.9000   33.8000   32.8000\n",
       "[torch.FloatTensor of size 28x500]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.LongTensor of size 316]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalize mean to 0\n",
    "train_input.sub_(train_input.mean())\n",
    "test_input.sub_(test_input.mean())\n",
    "\n",
    "# normalize variance to 1\n",
    "train_input.div_(train_input.std())\n",
    "test_input.div_(test_input.std())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg.fit(train_input.view(train_input.size(0),-1),train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = logistic_reg.predict(test_input.view(test_input.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0 % test error\n"
     ]
    }
   ],
   "source": [
    "print(100*((torch.LongTensor(pred) - test_target).abs().sum()/test_input.size(0)),\"% test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert targets to one hot labels\n",
    "#train_target = convert_to_one_hot_labels(train_input, train_target)\n",
    "#test_target = convert_to_one_hot_labels(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP = nn.Sequential(\n",
    "        nn.Linear(14000, 2000),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(2000, 1000),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(1000, 500),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(500, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 57.589459270238876\n",
      "1 54.4700927734375\n",
      "2 53.18478524684906\n",
      "3 52.266676515340805\n",
      "4 51.44706270098686\n",
      "5 50.63727232813835\n",
      "6 49.797384321689606\n"
     ]
    }
   ],
   "source": [
    "train_model(MLP, Variable(train_input.view(train_input.size(0),-1)), Variable(train_target), 4, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.10126582278481 % training accuracy\n"
     ]
    }
   ],
   "source": [
    "train_error_mlp = compute_nb_errors(MLP, Variable(train_input.view(train_input.size(0),-1)), Variable(train_target), 4)\n",
    "print(100*(train_error_mlp/train_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.0 % test accuracy\n"
     ]
    }
   ],
   "source": [
    "test_error_mlp = compute_nb_errors(MLP, Variable(test_input.view(test_input.size(0),-1)), Variable(test_target), 4)\n",
    "print(100*(test_error_mlp/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Basic_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(640, 2)\n",
    "        #self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(self.fc1(x.view(-1, 640)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = Basic_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56.95558702945709\n",
      "1 55.17108476161957\n",
      "2 54.6127405166626\n",
      "3 54.23999696969986\n",
      "4 53.803010284900665\n",
      "5 53.2659814953804\n",
      "6 52.64554297924042\n",
      "7 51.92966204881668\n",
      "8 51.13125231862068\n",
      "9 50.269792914390564\n",
      "10 49.34077298641205\n",
      "11 48.35625699162483\n",
      "12 47.332735031843185\n",
      "13 46.29627501964569\n",
      "14 45.25067150592804\n",
      "15 44.236146569252014\n",
      "16 43.25157728791237\n",
      "17 42.26177805662155\n",
      "18 41.302858635783195\n",
      "19 40.379487842321396\n",
      "20 39.49561505019665\n",
      "21 38.6313241571188\n",
      "22 37.78138419985771\n",
      "23 36.954672768712044\n",
      "24 36.12242315709591\n",
      "25 35.33122493326664\n",
      "26 34.535353884100914\n",
      "27 33.75711961090565\n",
      "28 32.99659049510956\n",
      "29 32.245732709765434\n",
      "30 31.51746292412281\n",
      "31 30.792341396212578\n",
      "32 30.08400596678257\n",
      "33 29.39134879410267\n",
      "34 28.69547264277935\n",
      "35 28.016396686434746\n",
      "36 27.314642563462257\n",
      "37 26.649529993534088\n",
      "38 25.974382311105728\n",
      "39 25.319012194871902\n",
      "40 24.667898908257484\n",
      "41 24.03805522620678\n",
      "42 23.403755843639374\n",
      "43 22.800414964556694\n",
      "44 22.19268999993801\n",
      "45 21.603420078754425\n",
      "46 21.03524860739708\n",
      "47 20.476434603333473\n",
      "48 19.938955649733543\n",
      "49 19.41890586912632\n",
      "50 18.933917731046677\n",
      "51 18.445203065872192\n",
      "52 17.994753375649452\n",
      "53 17.56889644265175\n",
      "54 17.153410881757736\n",
      "55 16.76842364668846\n",
      "56 16.408313393592834\n",
      "57 16.06114572286606\n",
      "58 15.737014025449753\n",
      "59 15.422405630350113\n",
      "60 15.14598335325718\n",
      "61 14.866725489497185\n",
      "62 14.613179594278336\n",
      "63 14.37206594645977\n",
      "64 14.152232617139816\n",
      "65 13.942598730325699\n",
      "66 13.748571336269379\n",
      "67 13.571028351783752\n",
      "68 13.40872186422348\n",
      "69 13.259063690900803\n",
      "70 13.117876052856445\n",
      "71 12.988225772976875\n",
      "72 12.86503355205059\n",
      "73 12.754340589046478\n",
      "74 12.647187784314156\n",
      "75 12.548239290714264\n",
      "76 12.454554751515388\n",
      "77 12.369111359119415\n",
      "78 12.286414474248886\n",
      "79 12.208974614739418\n",
      "80 12.135044932365417\n",
      "81 12.066541463136673\n",
      "82 12.000922307372093\n",
      "83 11.939684122800827\n",
      "84 11.88111026585102\n",
      "85 11.824670046567917\n",
      "86 11.77218647301197\n",
      "87 11.721904814243317\n",
      "88 11.674768522381783\n",
      "89 11.629044592380524\n",
      "90 11.584792658686638\n",
      "91 11.544039383530617\n",
      "92 11.504104509949684\n",
      "93 11.466581836342812\n",
      "94 11.430839106440544\n",
      "95 11.396659672260284\n",
      "96 11.363138318061829\n",
      "97 11.331990405917168\n",
      "98 11.301485300064087\n",
      "99 11.272520869970322\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn = compute_nb_errors(cnn, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "print(100*(train_error_cnn/train_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.0 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn = compute_nb_errors(cnn, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)\n",
    "print(100*(test_error_cnn/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_1D_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_1D_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(1,5))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(1,3))\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(1,5))\n",
    "        self.fc1 = nn.Linear(896*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), kernel_size=(1,2), stride=(1,2)))\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), kernel_size=(1,3), stride=(1,3)))\n",
    "        x = F.tanh(F.max_pool2d(self.conv3(x), kernel_size=(1,3), stride=(1,3)))\n",
    "        x = F.tanh(self.fc1(x.view(-1, 896*2)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2 = CNN_1D_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 55.39205425977707\n",
      "1 55.1071480512619\n",
      "2 54.88432043790817\n",
      "3 54.69542610645294\n",
      "4 54.52359253168106\n",
      "5 54.359900772571564\n",
      "6 54.19988948106766\n",
      "7 54.041609048843384\n",
      "8 53.88407105207443\n",
      "9 53.726076900959015\n",
      "10 53.56732773780823\n",
      "11 53.40670984983444\n",
      "12 53.24185699224472\n",
      "13 53.07051631808281\n",
      "14 52.88825523853302\n",
      "15 52.692460745573044\n",
      "16 52.479709684848785\n",
      "17 52.246079325675964\n",
      "18 51.988939255476\n",
      "19 51.703538089990616\n",
      "20 51.385479003190994\n",
      "21 51.03081238269806\n",
      "22 50.63576519489288\n",
      "23 50.194514483213425\n",
      "24 49.706726372241974\n",
      "25 49.16536131501198\n",
      "26 48.563020557165146\n",
      "27 47.89602488279343\n",
      "28 47.154321283102036\n",
      "29 46.337330371141434\n",
      "30 45.4395617544651\n",
      "31 44.458516985177994\n",
      "32 43.396443009376526\n",
      "33 42.26790724694729\n",
      "34 41.093894988298416\n",
      "35 39.89667738229036\n",
      "36 38.691021502017975\n",
      "37 37.50512535125017\n",
      "38 36.345744863152504\n",
      "39 35.214995697140694\n",
      "40 34.10999517515302\n",
      "41 33.02172859758139\n",
      "42 31.936698466539383\n",
      "43 30.86073984950781\n",
      "44 29.776862736791372\n",
      "45 28.681740574538708\n",
      "46 27.578361328691244\n",
      "47 26.470048014074564\n",
      "48 25.360580027103424\n",
      "49 24.25478858873248\n",
      "50 23.1486046127975\n",
      "51 22.043761804699898\n",
      "52 20.92612474784255\n",
      "53 19.82421814277768\n",
      "54 18.724528424441814\n",
      "55 17.645418390631676\n",
      "56 16.573408817872405\n",
      "57 15.520741617307067\n",
      "58 14.514678794890642\n",
      "59 13.536984093487263\n",
      "60 12.602559527382255\n",
      "61 11.691738868132234\n",
      "62 10.818844691850245\n",
      "63 9.972520391456783\n",
      "64 9.154076658189297\n",
      "65 8.35468835849315\n",
      "66 7.600591157563031\n",
      "67 6.884938291274011\n",
      "68 6.224086278118193\n",
      "69 5.61519745644182\n",
      "70 5.064336344599724\n",
      "71 4.570788067765534\n",
      "72 4.132539183367044\n",
      "73 3.7390270680189133\n",
      "74 3.388513293582946\n",
      "75 3.076404623221606\n",
      "76 2.8002923438325524\n",
      "77 2.5530953898560256\n",
      "78 2.3334749217610806\n",
      "79 2.1383799207396805\n",
      "80 1.9649755037389696\n",
      "81 1.8093277361476794\n",
      "82 1.6710884405765682\n",
      "83 1.5483429636224173\n",
      "84 1.437858464429155\n",
      "85 1.3392147911363281\n",
      "86 1.2502782219671644\n",
      "87 1.1694256814662367\n",
      "88 1.0967710525728762\n",
      "89 1.0302609305363148\n",
      "90 0.9699880421976559\n",
      "91 0.914730495918775\n",
      "92 0.8644206590543035\n",
      "93 0.8182503553689457\n",
      "94 0.775849382247543\n",
      "95 0.7367683601623867\n",
      "96 0.700753368641017\n",
      "97 0.6673832726373803\n",
      "98 0.636442330898717\n",
      "99 0.6078815326909535\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn2, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % training accuracy\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn2 = compute_nb_errors(cnn2, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "print(100*(train_error_cnn2/train_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.0 % test accuracy\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn2 = compute_nb_errors(cnn2, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)\n",
    "print(100*(test_error_cnn2/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_dropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(1,5))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(1,3))\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(1,5))\n",
    "        self.fc1 = nn.Linear(896*2, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), kernel_size=(1,2), stride=(1,2)))\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), kernel_size=(1,3), stride=(1,3)))\n",
    "        x = F.tanh(F.max_pool2d(self.conv3(x), kernel_size=(1,3), stride=(1,3)))\n",
    "        x = F.tanh(self.fc1(x.view(-1, 896*2)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3 = CNN_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 55.62590616941452\n",
      "1 55.27736222743988\n",
      "2 55.465994119644165\n",
      "3 55.13011175394058\n",
      "4 54.62331336736679\n",
      "5 54.70623528957367\n",
      "6 54.323948204517365\n",
      "7 55.064663767814636\n",
      "8 53.95391458272934\n",
      "9 54.26176428794861\n",
      "10 53.94095003604889\n",
      "11 54.08088171482086\n",
      "12 53.88814002275467\n",
      "13 53.240974962711334\n",
      "14 53.853637993335724\n",
      "15 52.81994903087616\n",
      "16 53.00178104639053\n",
      "17 52.412420988082886\n",
      "18 53.26144856214523\n",
      "19 52.715313613414764\n",
      "20 52.17420816421509\n",
      "21 51.51333495974541\n",
      "22 51.85226258635521\n",
      "23 51.53934422135353\n",
      "24 51.13265988230705\n",
      "25 50.231587171554565\n",
      "26 51.0381962954998\n",
      "27 49.86157310009003\n",
      "28 48.728099793195724\n",
      "29 48.26133918762207\n",
      "30 47.89814227819443\n",
      "31 48.237604796886444\n",
      "32 46.760788798332214\n",
      "33 45.7238205075264\n",
      "34 44.2342529296875\n",
      "35 42.87521901726723\n",
      "36 43.48777060210705\n",
      "37 41.513620391488075\n",
      "38 40.61492016911507\n",
      "39 38.90208052098751\n",
      "40 38.162267208099365\n",
      "41 36.51222175359726\n",
      "42 34.208058044314384\n",
      "43 32.96465936303139\n",
      "44 31.46438953280449\n",
      "45 29.536835372447968\n",
      "46 27.349474877119064\n",
      "47 26.71925824135542\n",
      "48 24.925119511783123\n",
      "49 22.069118432700634\n",
      "50 19.524189598858356\n",
      "51 19.03940197825432\n",
      "52 17.939580161124468\n",
      "53 14.19894733466208\n",
      "54 13.505112700164318\n",
      "55 12.131167167797685\n",
      "56 11.181241286918521\n",
      "57 9.394026974216104\n",
      "58 8.166712744161487\n",
      "59 7.420490221120417\n",
      "60 6.6958062797784805\n",
      "61 4.981835562735796\n",
      "62 4.948868682608008\n",
      "63 4.412245347630233\n",
      "64 3.514711743686348\n",
      "65 2.9395543606951833\n",
      "66 2.652675101067871\n",
      "67 2.540543808368966\n",
      "68 2.098888044944033\n",
      "69 1.776406564982608\n",
      "70 1.8819196125259623\n",
      "71 1.5290649181697518\n",
      "72 1.4325969809433445\n",
      "73 1.371418262599036\n",
      "74 1.161927877634298\n",
      "75 1.2715672669000924\n",
      "76 1.1086530041648075\n",
      "77 0.9862012343946844\n",
      "78 0.8004781021736562\n",
      "79 0.8265430239844136\n",
      "80 0.7229930572211742\n",
      "81 0.8160299092996866\n",
      "82 0.7728406138485298\n",
      "83 0.7884200293337926\n",
      "84 0.6170815642690286\n",
      "85 0.6087854605866596\n",
      "86 0.5607916751760058\n",
      "87 0.4745781552628614\n",
      "88 0.5293591457157163\n",
      "89 0.5080688955204096\n",
      "90 0.5344057820911985\n",
      "91 0.4349889309378341\n",
      "92 0.44687582238111645\n",
      "93 0.3860698079079157\n",
      "94 0.45759949277271517\n",
      "95 0.45852319401456043\n",
      "96 0.36218240088783205\n",
      "97 0.37250053783645853\n",
      "98 0.3389066226372961\n",
      "99 0.3667919459985569\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn3, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn3 = compute_nb_errors(cnn3, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "print(100*(train_error_cnn3/train_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.999999999999996 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn3 = compute_nb_errors(cnn3, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)\n",
    "print(100*(test_error_cnn3/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
