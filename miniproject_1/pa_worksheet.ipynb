{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "import dlc_bci as bci\n",
    "from helpers import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,10)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input : <class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "Train target : <class 'torch.LongTensor'> torch.Size([316])\n",
      "Test input : <class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "Test target : <class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Subset of data sampled at 100Hz\n",
    "train_input , train_target = bci.load(root = './data_bci')\n",
    "print(\"Train input :\", str(type(train_input)), train_input.size()) \n",
    "print(\"Train target :\", str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False)\n",
    "print(\"Test input :\", str(type(test_input)), test_input.size()) \n",
    "print(\"Test target :\", str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input : <class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "Train target : <class 'torch.LongTensor'> torch.Size([316])\n",
      "Test input : <class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "Test target : <class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Full data sampled at 1Khz\n",
    "train_input , train_target = bci.load(root = './data_bci', one_khz = True)\n",
    "print(\"Train input :\", str(type(train_input)), train_input.size()) \n",
    "print(\"Train target :\", str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False, one_khz = True)\n",
    "print(\"Test input :\", str(type(test_input)), test_input.size()) \n",
    "print(\"Test target :\", str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  30.8000   33.1000   37.9000  ...    76.9000   75.9000   72.3000\n",
       " -22.6000  -19.2000  -11.8000  ...    26.8000   22.9000   16.4000\n",
       "  11.2000   16.7000   26.4000  ...    64.1000   62.0000   55.9000\n",
       "             ...                ⋱                ...             \n",
       "   0.5000    0.5000    0.4000  ...    45.1000   46.2000   46.6000\n",
       "  11.0000   10.6000    9.8000  ...    41.7000   41.5000   40.9000\n",
       "  -9.9000  -10.0000  -10.3000  ...    32.9000   33.8000   32.8000\n",
       "[torch.FloatTensor of size 28x500]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.LongTensor of size 316]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "Normalizing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mean = train_input.mean(2).mean(0).unsqueeze(1).expand(-1,train_input.size(2))\n",
    "train_std = train_input.std(2).std(0).unsqueeze(1).expand(-1,train_input.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_mean = test_input.mean(2).mean(0).unsqueeze(1).expand(-1,test_input.size(2))\n",
    "test_std = test_input.std(2).std(0).unsqueeze(1).expand(-1,test_input.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalize mean to 0\n",
    "train_input.sub_(train_mean)\n",
    "test_input.sub_(test_mean)\n",
    "\n",
    "# normalize variance to 1\n",
    "train_input.div_(train_input.std())\n",
    "test_input.div_(test_input.std())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window slicing for data augmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = [ train_input[:,:,i::10] for i in range(10) ]\n",
    "train_input = torch.cat(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = torch.cat([train_target]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = [ test_input[:,:,i::10] for i in range(10) ]\n",
    "test_input = torch.cat(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_target = torch.cat([test_target]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0  ,.,.) = \n",
       " -1.1184e+00 -6.6277e-01 -1.1995e+00  ...   4.5434e-01 -2.1655e-01  3.7009e-01\n",
       " -6.8330e-01  7.6446e-05 -7.4883e-01  ...   1.0049e+00  8.7448e-02  1.0891e+00\n",
       " -1.1344e+00 -6.4085e-02 -1.1812e+00  ...   9.9686e-01 -3.5741e-01  1.2122e+00\n",
       "                 ...                   ⋱                   ...                \n",
       " -3.4267e-01 -2.2721e-01 -7.1193e-02  ...   8.4621e-01  8.3997e-01  7.6820e-01\n",
       " -3.7571e-01 -1.5416e-01  2.5774e-01  ...   9.5359e-01  9.5359e-01  6.4467e-01\n",
       " -5.9022e-01 -3.2186e-01 -5.3502e-02  ...   8.7327e-01  8.9511e-01  6.1739e-01\n",
       "\n",
       "( 1  ,.,.) = \n",
       "  2.1550e+00  2.1269e+00  2.4670e+00  ...   3.4825e-01  7.7262e-01  5.7604e-01\n",
       "  5.4927e-01  4.3762e-02  6.2416e-01  ...  -1.2356e+00 -3.5877e-01 -1.0234e+00\n",
       " -7.3810e-01 -1.1999e+00 -7.4434e-01  ...  -2.0424e+00 -1.2623e+00 -1.8958e+00\n",
       "                 ...                   ⋱                   ...                \n",
       " -9.4491e-01 -8.7938e-01 -1.2351e+00  ...  -1.3225e+00 -9.8548e-01 -8.4194e-01\n",
       " -5.2861e-01 -5.3797e-01 -8.6874e-01  ...  -9.2802e-01 -4.1939e-01 -1.2607e-01\n",
       " -1.1394e+00 -8.5857e-01 -1.2205e+00  ...  -1.6543e+00 -1.2892e+00 -8.3673e-01\n",
       "\n",
       "( 2  ,.,.) = \n",
       "  8.6130e-02 -3.0080e-01  3.0456e-01  ...  -3.4449e-01  3.3082e-02 -2.3839e-01\n",
       "  4.3382e-01 -4.7735e-01  6.2728e-01  ...  -2.7452e-01  4.9935e-01 -2.5580e-01\n",
       "  4.9447e-01 -8.0675e-01  6.2553e-01  ...  -6.1640e-01  5.1007e-01 -5.7584e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -2.5842e-01  1.2851e-01  1.5036e-01  ...   2.2420e-02 -3.4579e-01  2.6893e-01\n",
       " -5.5669e-01  3.5447e-01  3.2951e-01  ...   5.1361e-01 -1.8536e-01  4.8670e-02\n",
       " -9.0226e-01 -6.9104e-02  4.1144e-01  ...   2.1486e-01 -2.1264e-01  4.1456e-01\n",
       " ... \n",
       "\n",
       "(3157,.,.) = \n",
       "  7.2270e-01  5.1675e-01  1.6102e-01  ...   9.2371e-02  3.3082e-02  1.1733e-01\n",
       "  3.9325e-01  1.5610e-01 -6.8573e-02  ...  -2.9948e-01 -3.3381e-01 -3.1197e-01\n",
       "  1.8555e-01  4.1646e-01 -2.2323e-01  ...  -5.4724e-02 -5.8832e-01 -1.4210e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.3773e-01 -3.0627e-02 -5.5486e-01  ...  -2.8026e-01 -5.3302e-01 -4.0508e-01\n",
       " -7.3027e-02 -8.3753e-01 -1.4710e+00  ...   7.3634e-02 -4.1822e-02 -4.4943e-02\n",
       "  1.1500e-01 -5.5589e-01 -1.3890e+00  ...   1.4309e-01 -1.4087e-01 -4.7261e-02\n",
       "\n",
       "(3158,.,.) = \n",
       " -1.6844e-02  7.5078e-01  5.4795e-01  ...   1.2357e-01 -3.6945e-01 -9.1735e-02\n",
       "  3.8701e-01  1.4043e+00  1.1359e+00  ...   6.4288e-01  1.5679e-02  4.6814e-01\n",
       "  6.7546e-01  1.8331e+00  1.3027e+00  ...   1.1622e+00  1.8243e-01  9.8438e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  5.9970e-01  8.7118e-01  8.1501e-01  ...   2.5333e-01  1.0979e-01  3.1781e-02\n",
       "  5.5418e-01  6.3843e-01  1.3916e-01  ...   2.9518e-01  1.7661e-01  2.6827e-02\n",
       "  5.6434e-01  6.7980e-01  2.8663e-01  ...   3.6776e-01  3.3031e-01  5.2593e-02\n",
       "\n",
       "(3159,.,.) = \n",
       " -1.6844e-02  5.0739e-01  1.5790e-01  ...   5.6356e-01  1.0797e-01  5.2611e-01\n",
       "  5.2119e-01  1.5291e+00  4.6190e-01  ...   1.4074e+00  5.0871e-01  1.2857e+00\n",
       "  1.2715e+00  2.3542e+00  1.0967e+00  ...   2.3605e+00  1.1498e+00  2.1545e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  2.3253e+00  2.2473e+00  2.4688e+00  ...   2.1630e+00  2.4688e+00  2.3409e+00\n",
       "  2.4888e+00  2.5949e+00  2.8321e+00  ...   2.0145e+00  2.3172e+00  2.1362e+00\n",
       "  2.9078e+00  2.8579e+00  3.2354e+00  ...   2.0746e+00  2.7362e+00  2.9078e+00\n",
       "[torch.FloatTensor of size 3160x28x50]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting training and validation sets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_input.size(0))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_input = train_input.clone()\n",
    "train_input = full_input[indices[:split].tolist()]\n",
    "validation_input = full_input[indices[split:].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_target = train_target.clone()\n",
    "train_target = full_target[indices[:split].tolist()]\n",
    "validation_target = full_target[indices[split:].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.fit(train_input.view(train_input.size(0),-1),train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_pred_train = discrete_predictions(torch.FloatTensor(linear_reg.predict(train_input.view(train_input.size(0),-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % train error\n"
     ]
    }
   ],
   "source": [
    "print(100*((linear_pred_train - train_target).abs().sum()/train_input.size(0)),\"% train error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_pred_test = discrete_predictions(torch.FloatTensor(linear_reg.predict(test_input.view(test_input.size(0),-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.9 % test error\n"
     ]
    }
   ],
   "source": [
    "print(100*((linear_pred_test - test_target).abs().sum()/test_input.size(0)),\"% test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_reg = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.fit(train_input.view(train_input.size(0),-1),train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_pred_train = discrete_predictions(torch.FloatTensor(ridge_reg.predict(train_input.view(train_input.size(0),-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % train error\n"
     ]
    }
   ],
   "source": [
    "print(100*((ridge_pred_train - train_target).abs().sum()/train_input.size(0)),\"% train error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_pred_test = discrete_predictions(torch.FloatTensor(ridge_reg.predict(test_input.view(test_input.size(0),-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.9 % test error\n"
     ]
    }
   ],
   "source": [
    "print(100*((ridge_pred_test - test_target).abs().sum()/test_input.size(0)),\"% test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg.fit(train_input.view(train_input.size(0),-1),train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_pred_train = torch.LongTensor(logistic_reg.predict(train_input.view(train_input.size(0),-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % train error\n"
     ]
    }
   ],
   "source": [
    "print(100*((logistic_pred_train - train_target).abs().sum()/train_input.size(0)),\"% train error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_pred_test = logistic_reg.predict(test_input.view(test_input.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.000000000000004 % test error\n"
     ]
    }
   ],
   "source": [
    "print(100*((logistic_pred_test - test_target).abs().sum()/test_input.size(0)),\"% test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP = nn.Sequential(\n",
    "        nn.Linear(1400, 140),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(140, 28),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(28, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 44.072047382593155\n",
      "Epoch 10 loss = 9.844592585228384\n",
      "Epoch 20 loss = 6.37521896418184\n",
      "Epoch 30 loss = 0.04982630047015846\n",
      "Epoch 40 loss = 0.01820115691953106\n",
      "Epoch 50 loss = 0.009272573479393031\n",
      "Epoch 60 loss = 0.00532340435529477\n",
      "Epoch 70 loss = 0.0032243903369817417\n",
      "Epoch 80 loss = 0.0020220179230818758\n",
      "Epoch 90 loss = 0.0012823412580473814\n",
      "Epoch 100 loss = 0.0008373723703698488\n"
     ]
    }
   ],
   "source": [
    "train_model(MLP, Variable(full_input.view(full_input.size(0),-1)), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_mlp = compute_nb_errors(MLP, Variable(full_input.view(full_input.size(0),-1)), Variable(full_target))\n",
    "print(100*(train_error_mlp/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.5 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_mlp = compute_nb_errors(MLP, Variable(test_input.view(test_input.size(0),-1)), Variable(test_target))\n",
    "print(100*(test_error_mlp/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Basic_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Basic_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128, 28)\n",
    "        self.fc2 = nn.Linear(28, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), kernel_size=(3,2), stride=(3,2)))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = F.tanh(self.fc1(x.view(x.size(0),-1)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = Basic_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(cnn, Variable(full_input.unsqueeze(1)), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn = compute_nb_errors(cnn, Variable(full_input.unsqueeze(1)), Variable(full_target))\n",
    "print(100*(train_error_cnn/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.4 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn = compute_nb_errors(cnn, Variable(test_input.unsqueeze(1)), Variable(test_target))\n",
    "print(100*(test_error_cnn/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN w 1D filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 28, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(28, 14, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(14, 1, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(9, 36)\n",
    "        self.fc2 = nn.Linear(36, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = self.fc1(x.squeeze(1))\n",
    "        x = self.fc2(F.tanh(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 52.112239360809326\n",
      "Epoch 10 loss = 6.469338921830058\n",
      "Epoch 20 loss = 0.2049055152456276\n",
      "Epoch 30 loss = 0.04752383720187936\n",
      "Epoch 40 loss = 0.019488050551444758\n",
      "Epoch 50 loss = 0.009714462295960402\n",
      "Epoch 60 loss = 0.0053200298571027815\n",
      "Epoch 70 loss = 0.003074018642109877\n",
      "Epoch 80 loss = 0.0018293963439646177\n",
      "Epoch 90 loss = 0.0011096503940279945\n",
      "Epoch 100 loss = 0.0006824515285188681\n"
     ]
    }
   ],
   "source": [
    "cnn_1D = CNN_1D()\n",
    "train_model(cnn_1D, Variable(full_input), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn_1D = compute_nb_errors(cnn_1D, Variable(full_input), Variable(full_target))\n",
    "print(100*(train_error_cnn_1D/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn_1D = compute_nb_errors(cnn_1D, Variable(test_input), Variable(test_target))\n",
    "print(100*(test_error_cnn_1D/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### previous + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_dropout(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(CNN_dropout, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 28, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(28, 14, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(14, 1, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(9, 30)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(30, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = self.fc1(x.squeeze(1))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(F.tanh(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 54.21390461921692\n",
      "Epoch 10 loss = 13.391567431390285\n",
      "Epoch 20 loss = 0.602470112266019\n",
      "Epoch 30 loss = 0.16750079122721218\n",
      "Epoch 40 loss = 0.073359655601962\n",
      "Epoch 50 loss = 0.03508611716097221\n",
      "Epoch 60 loss = 0.030605764273786917\n",
      "Epoch 70 loss = 0.10801360759069212\n",
      "Epoch 80 loss = 0.04040353424352361\n",
      "Epoch 90 loss = 0.01755940921975707\n",
      "Epoch 100 loss = 0.01218668266574241\n"
     ]
    }
   ],
   "source": [
    "cnn_drop = CNN_dropout()\n",
    "train_model(cnn_drop, Variable(full_input), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn_drop = compute_nb_errors(cnn_drop, Variable(full_input), Variable(full_target))\n",
    "print(100*(train_error_cnn_drop/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn_drop = compute_nb_errors(cnn_drop, Variable(test_input), Variable(test_target))\n",
    "print(100*(test_error_cnn_drop/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_batchnorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_batchnorm, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 28, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(28)\n",
    "        self.conv2 = nn.Conv1d(28, 14, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(14)\n",
    "        self.conv3 = nn.Conv1d(14, 1, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(1)\n",
    "        self.fc1 = nn.Linear(9, 30)\n",
    "        self.bn4 = nn.BatchNorm1d(30)\n",
    "        self.fc2 = nn.Linear(30, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool1d(self.bn1(self.conv1(x)), kernel_size=2, stride=2))\n",
    "        x = F.tanh(F.max_pool1d(self.bn2(self.conv2(x)), kernel_size=2, stride=2))\n",
    "        x = F.tanh(self.bn3(self.conv3(x)))\n",
    "        x = self.fc1(x.squeeze(1))\n",
    "        x = self.fc2(F.tanh(self.bn4(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 49.73396196961403\n",
      "Epoch 10 loss = 2.693355151452124\n",
      "Epoch 20 loss = 0.20191391304251738\n",
      "Epoch 30 loss = 0.026976141351042315\n",
      "Epoch 40 loss = 0.013303212912433082\n",
      "Epoch 50 loss = 0.007391592858766671\n",
      "Epoch 60 loss = 0.0043405275700934\n",
      "Epoch 70 loss = 0.0026283940233042813\n",
      "Epoch 80 loss = 0.0016277259023809165\n",
      "Epoch 90 loss = 0.0010235974186798558\n",
      "Epoch 100 loss = 0.0006506333036213618\n"
     ]
    }
   ],
   "source": [
    "cnn_norm = CNN_batchnorm()\n",
    "train_model(cnn_norm, Variable(full_input), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03164556962025317 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn_norm = compute_nb_errors(cnn_norm, Variable(full_input), Variable(full_target))\n",
    "print(100*(train_error_cnn_norm/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn_norm = compute_nb_errors(cnn_norm, Variable(test_input), Variable(test_target))\n",
    "print(100*(test_error_cnn_norm/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_both(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(CNN_both, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 28, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(28)\n",
    "        self.conv2 = nn.Conv1d(28, 14, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(14)\n",
    "        self.conv3 = nn.Conv1d(14, 1, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(1)\n",
    "        self.fc1 = nn.Linear(9, 30)\n",
    "        self.bn4 = nn.BatchNorm1d(30)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(30, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool1d(self.bn1(self.conv1(x)), kernel_size=2, stride=2))\n",
    "        x = F.tanh(F.max_pool1d(self.bn2(self.conv2(x)), kernel_size=2, stride=2))\n",
    "        x = F.tanh(self.bn3(self.conv3(x)))\n",
    "        x = self.fc1(x.squeeze(1))\n",
    "        x = self.dropout(self.bn4(x))\n",
    "        x = self.fc2(F.tanh(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 53.4827983379364\n",
      "Epoch 10 loss = 3.010024955496192\n",
      "Epoch 20 loss = 0.169668891641777\n",
      "Epoch 30 loss = 4.367536114295945\n",
      "Epoch 40 loss = 0.0749251453235047\n",
      "Epoch 50 loss = 0.03644149238243699\n",
      "Epoch 60 loss = 0.019753706072151545\n",
      "Epoch 70 loss = 0.014550293459251407\n",
      "Epoch 80 loss = 1.8616079927887768\n",
      "Epoch 90 loss = 0.082001906062942\n",
      "Epoch 100 loss = 0.03303353711817181\n"
     ]
    }
   ],
   "source": [
    "cnn_both = CNN_both()\n",
    "train_model(cnn_both, Variable(full_input), Variable(full_target), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06329113924050633 % training error\n"
     ]
    }
   ],
   "source": [
    "train_error_cnn_both = compute_nb_errors(cnn_both, Variable(full_input), Variable(full_target))\n",
    "print(100*(train_error_cnn_both/full_input.size(0)),'% training error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.700000000000003 % test error\n"
     ]
    }
   ],
   "source": [
    "test_error_cnn_both = compute_nb_errors(cnn_both, Variable(test_input), Variable(test_target))\n",
    "print(100*(test_error_cnn_both/test_input.size(0)),'% test error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_params(network, train_input, train_target, val_input, val_target, learning_rates, nb_epochs_total, epoch_step, mini_batch_size):\n",
    "    res = []\n",
    "    best_error = val_input.size(0)+1\n",
    "    #print(\"MLP\")\n",
    "    print(\"MODEL\", network().__class__.__name__)\n",
    "    print(\"=\"*18)\n",
    "    for lr in learning_rates: \n",
    "        print(\"  Learning rate\", lr, \":\")\n",
    "        print(\"-\"*23)\n",
    "        epoch_acc = []\n",
    "        model = network()\n",
    "        #model = nn.Sequential(\n",
    "        #    nn.Linear(1400, 140),\n",
    "        #    nn.Tanh(),\n",
    "        #    nn.Linear(140, 28),\n",
    "        #    nn.Tanh(),\n",
    "        #    nn.Linear(28, 2)\n",
    "        #)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        for e in range(nb_epochs_total):\n",
    "            sum_loss = 0\n",
    "            model.train()\n",
    "            for b in range(0, train_input.size(0), mini_batch_size):\n",
    "                output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "                loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "                sum_loss = sum_loss + loss.data[0]\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            if (e+1)%epoch_step == 0 or e==0:\n",
    "                validation_error = compute_nb_errors(model, val_input, val_target)\n",
    "                if (e+1)%(10*epoch_step) == 0 or e==0:\n",
    "                    print(\"    Epoch {:>4} : loss = {:1.8f} | validation error = {:>4}\".format(e+1, sum_loss, validation_error))\n",
    "                epoch_acc.append(100*(validation_error/val_input.size(0)))\n",
    "                if (validation_error < best_error) or ( (validation_error == best_error) and ((e+1) < best_epoch) ):\n",
    "                    best_error = validation_error\n",
    "                    best_epoch = e+1\n",
    "                    best_lr = lr\n",
    "                    \n",
    "        res.append(epoch_acc)\n",
    "    print(\"Done.\")\n",
    "    return res, best_epoch, best_lr, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0025, 0.005, 0.0075, 0.01]\n",
    "nb_epochs_total = 500\n",
    "epoch_step = 5\n",
    "mini_batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.72939926 | validation error =  238\n",
      "    Epoch   50 : loss = 0.02746910 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00958435 | validation error =    0\n",
      "    Epoch  150 : loss = 0.00356965 | validation error =    0\n",
      "    Epoch  200 : loss = 0.00183774 | validation error =    0\n",
      "    Epoch  250 : loss = 0.00113654 | validation error =    0\n",
      "    Epoch  300 : loss = 0.00075911 | validation error =    0\n",
      "    Epoch  350 : loss = 0.00052780 | validation error =    0\n",
      "    Epoch  400 : loss = 0.00037670 | validation error =    0\n",
      "    Epoch  450 : loss = 0.00027348 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00020099 | validation error =    0\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.78789276 | validation error =  208\n",
      "    Epoch   50 : loss = 0.02694813 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00219738 | validation error =    0\n",
      "    Epoch  150 : loss = 0.00103722 | validation error =    0\n",
      "    Epoch  200 : loss = 0.00058790 | validation error =    0\n",
      "    Epoch  250 : loss = 0.00036425 | validation error =    0\n",
      "    Epoch  300 : loss = 0.00023390 | validation error =    0\n",
      "    Epoch  350 : loss = 0.00015953 | validation error =    0\n",
      "    Epoch  400 : loss = 0.00011296 | validation error =    0\n",
      "    Epoch  450 : loss = 0.00008190 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00006031 | validation error =    0\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.31401211 | validation error =  311\n",
      "    Epoch   50 : loss = 0.65189491 | validation error =   21\n",
      "    Epoch  100 : loss = 0.98933707 | validation error =   40\n",
      "    Epoch  150 : loss = 0.29365994 | validation error =   13\n",
      "    Epoch  200 : loss = 0.83468929 | validation error =   20\n",
      "    Epoch  250 : loss = 0.54667439 | validation error =   16\n",
      "    Epoch  300 : loss = 0.18662780 | validation error =    7\n",
      "    Epoch  350 : loss = 0.18435616 | validation error =    7\n",
      "    Epoch  400 : loss = 0.18340698 | validation error =    5\n",
      "    Epoch  450 : loss = 0.18251016 | validation error =    5\n",
      "    Epoch  500 : loss = 0.18195362 | validation error =    5\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.89068532 | validation error =  254\n",
      "    Epoch   50 : loss = 1.10992810 | validation error =   34\n",
      "    Epoch  100 : loss = 1.43832108 | validation error =   46\n",
      "    Epoch  150 : loss = 0.76380866 | validation error =   19\n",
      "    Epoch  200 : loss = 2.97109476 | validation error =  116\n",
      "    Epoch  250 : loss = 1.11910153 | validation error =   46\n",
      "    Epoch  300 : loss = 0.66780862 | validation error =   22\n",
      "    Epoch  350 : loss = 0.26472971 | validation error =   16\n",
      "    Epoch  400 : loss = 0.25345047 | validation error =   16\n",
      "    Epoch  450 : loss = 0.25181309 | validation error =   15\n",
      "    Epoch  500 : loss = 0.25051636 | validation error =   15\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.08526009 | validation error =  235\n",
      "    Epoch   50 : loss = 2.57090797 | validation error =   78\n",
      "    Epoch  100 : loss = 1.63984670 | validation error =   44\n",
      "    Epoch  150 : loss = 2.69728848 | validation error =  114\n",
      "    Epoch  200 : loss = 3.92531106 | validation error =  114\n",
      "    Epoch  250 : loss = 1.78405957 | validation error =   75\n",
      "    Epoch  300 : loss = 1.20516432 | validation error =   57\n",
      "    Epoch  350 : loss = 0.73204131 | validation error =   22\n",
      "    Epoch  400 : loss = 1.36669156 | validation error =   33\n",
      "    Epoch  450 : loss = 1.05462773 | validation error =   30\n",
      "    Epoch  500 : loss = 0.78890195 | validation error =   25\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "all_results, best_epoch, best_lr, best_error = find_best_params(MLP, Variable(train_input.view(train_input.size(0),-1)), Variable(train_target), Variable(validation_input.view(validation_input.size(0),-1)), Variable(validation_target), learning_rates, nb_epochs_total, epoch_step, mini_batch_size)\n",
    "json_res = {\"model\":\"MLP\",   \"learning_rates\":learning_rates, \"nb_epochs_total\":nb_epochs_total, \"epoch_step\":epoch_step, \"mini_batch_size\":mini_batch_size, \"best_epoch\":best_epoch, \"best_lr\":best_lr, \"best_error\":best_error, \"results\":all_results}\n",
    "json.dump(json_res,open('results/adam/'+json_res[\"model\"]+'.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic CNN test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0025, 0.005, 0.0075, 0.01]\n",
    "nb_epochs_total = 100\n",
    "epoch_step = 5\n",
    "mini_batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Basic_CNN\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.93463784 | validation error =  288\n",
      "    Epoch   50 : loss = 0.01172235 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00257484 | validation error =    0\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.93030840 | validation error =  302\n",
      "    Epoch   50 : loss = 0.00179214 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00050704 | validation error =    0\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.87247020 | validation error =  280\n",
      "    Epoch   50 : loss = 0.00050149 | validation error =    3\n",
      "    Epoch  100 : loss = 0.00016828 | validation error =    3\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.09767592 | validation error =  338\n",
      "    Epoch   50 : loss = 0.00077433 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00025720 | validation error =    0\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.15163642 | validation error =  337\n",
      "    Epoch   50 : loss = 0.00083945 | validation error =    0\n",
      "    Epoch  100 : loss = 0.00026890 | validation error =    0\n",
      "Done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-8e1204ab43ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasic_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjson_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m\"learning_rates\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nb_epochs_total\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnb_epochs_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch_step\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mini_batch_size\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_lr\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbest_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbest_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"results\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/adam/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mjson_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "all_results, best_epoch, best_lr, best_error = find_best_params(Basic_CNN, Variable(train_input.unsqueeze(1)), Variable(train_target), Variable(validation_input.unsqueeze(1)), Variable(validation_target), learning_rates, nb_epochs_total, epoch_step, mini_batch_size)\n",
    "json_res = {\"model\":\"Basic_CNN\",   \"learning_rates\":learning_rates, \"nb_epochs_total\":nb_epochs_total, \"epoch_step\":epoch_step, \"mini_batch_size\":mini_batch_size, \"best_epoch\":best_epoch, \"best_lr\":best_lr, \"best_error\":best_error, \"results\":all_results}\n",
    "json.dump(json_res,open('results/adam/'+json_res[\"model\"]+'.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the 4 other models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0025, 0.005, 0.0075, 0.01]\n",
    "nb_epochs_total = 2000\n",
    "epoch_step = 10\n",
    "mini_batch_size = 250\n",
    "\n",
    "models = [ CNN_1D, CNN_dropout, CNN_batchnorm, CNN_both ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL CNN_1D\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.90667015 | validation error =  268\n",
      "    Epoch  100 : loss = 0.02529639 | validation error =    3\n",
      "    Epoch  200 : loss = 0.02296719 | validation error =    4\n",
      "    Epoch  300 : loss = 0.00402738 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00167221 | validation error =    2\n",
      "    Epoch  500 : loss = 0.00081492 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00042553 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00023059 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00012739 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00007127 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00004026 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00002287 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00001305 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00000747 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00000429 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00000247 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00000142 | validation error =    1\n",
      "    Epoch 1700 : loss = 0.00000082 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00000048 | validation error =    1\n",
      "    Epoch 1900 : loss = 0.00000028 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.00000016 | validation error =    1\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.86958516 | validation error =  248\n",
      "    Epoch  100 : loss = 0.00203791 | validation error =    4\n",
      "    Epoch  200 : loss = 0.00046660 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00017801 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00008186 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00004123 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00002189 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00001198 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00000667 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00000376 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00000214 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00000122 | validation error =    0\n",
      "    Epoch 1200 : loss = 0.00000071 | validation error =    0\n",
      "    Epoch 1300 : loss = 0.00000041 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00000024 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00000014 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00000008 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00000005 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00000003 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00000002 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00000001 | validation error =    0\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.79843348 | validation error =  217\n",
      "    Epoch  100 : loss = 0.00107376 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00023185 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00008936 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00004184 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00002141 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00001151 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00000636 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00000359 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00000205 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00000118 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00000068 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00000039 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00000023 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00000013 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00000008 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00000005 | validation error =    1\n",
      "    Epoch 1700 : loss = 0.00000003 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00000002 | validation error =    1\n",
      "    Epoch 1900 : loss = 0.00000001 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.00000001 | validation error =    1\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.89691937 | validation error =  242\n",
      "    Epoch  100 : loss = 0.00031112 | validation error =    2\n",
      "    Epoch  200 : loss = 0.00007962 | validation error =    2\n",
      "    Epoch  300 : loss = 0.00003196 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00001522 | validation error =    2\n",
      "    Epoch  500 : loss = 0.00000788 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00000428 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00000238 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00000135 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00000077 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00000045 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00000026 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00000015 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00000009 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00000005 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00000003 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00000002 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00000000 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00000000 | validation error =    0\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.76421958 | validation error =  254\n",
      "    Epoch  100 : loss = 0.00019162 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00005607 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00002356 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00001150 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00000604 | validation error =    0\n",
      "    Epoch  600 : loss = 0.00000330 | validation error =    0\n",
      "    Epoch  700 : loss = 0.00000185 | validation error =    0\n",
      "    Epoch  800 : loss = 0.00000105 | validation error =    0\n",
      "    Epoch  900 : loss = 0.00000060 | validation error =    0\n",
      "    Epoch 1000 : loss = 0.00000035 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00000020 | validation error =    0\n",
      "    Epoch 1200 : loss = 0.00000012 | validation error =    0\n",
      "    Epoch 1300 : loss = 0.00000007 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00000004 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00000002 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00000000 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00000000 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00000000 | validation error =    0\n",
      "Done.\n",
      "\n",
      "MODEL CNN_dropout\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.96165621 | validation error =  253\n",
      "    Epoch  100 : loss = 0.04247727 | validation error =    9\n",
      "    Epoch  200 : loss = 0.00821017 | validation error =    3\n",
      "    Epoch  300 : loss = 0.00378370 | validation error =    3\n",
      "    Epoch  400 : loss = 0.00128016 | validation error =    3\n",
      "    Epoch  500 : loss = 0.00093038 | validation error =    3\n",
      "    Epoch  600 : loss = 0.00062957 | validation error =    3\n",
      "    Epoch  700 : loss = 0.00030249 | validation error =    2\n",
      "    Epoch  800 : loss = 0.00015051 | validation error =    2\n",
      "    Epoch  900 : loss = 0.00007766 | validation error =    2\n",
      "    Epoch 1000 : loss = 0.00006103 | validation error =    2\n",
      "    Epoch 1100 : loss = 0.00002951 | validation error =    4\n",
      "    Epoch 1200 : loss = 0.00441033 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00190031 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00114223 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00068669 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00052016 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00029647 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00022541 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00018187 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.19193929 | validation error =    6\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.01799899 | validation error =  285\n",
      "    Epoch  100 : loss = 0.00563946 | validation error =    3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch  200 : loss = 0.00156475 | validation error =    3\n",
      "    Epoch  300 : loss = 0.00070534 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00025862 | validation error =    2\n",
      "    Epoch  500 : loss = 0.16858541 | validation error =    5\n",
      "    Epoch  600 : loss = 0.00899296 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00444982 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00167385 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00101449 | validation error =    2\n",
      "    Epoch 1000 : loss = 0.01350705 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00333197 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00142907 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00085913 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00048945 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00020497 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00764812 | validation error =    2\n",
      "    Epoch 1700 : loss = 0.00250055 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00126569 | validation error =    1\n",
      "    Epoch 1900 : loss = 0.00106047 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.01166455 | validation error =    1\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.17296541 | validation error =  293\n",
      "    Epoch  100 : loss = 0.00254948 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00049547 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00035345 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00019339 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00009247 | validation error =    0\n",
      "    Epoch  600 : loss = 0.00005174 | validation error =    0\n",
      "    Epoch  700 : loss = 0.00003473 | validation error =    0\n",
      "    Epoch  800 : loss = 1.06642449 | validation error =   62\n",
      "    Epoch  900 : loss = 0.00285406 | validation error =    0\n",
      "    Epoch 1000 : loss = 0.00194349 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00058446 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.19293690 | validation error =   12\n",
      "    Epoch 1300 : loss = 0.00167525 | validation error =    4\n",
      "    Epoch 1400 : loss = 0.00122721 | validation error =    3\n",
      "    Epoch 1500 : loss = 0.00038553 | validation error =    3\n",
      "    Epoch 1600 : loss = 0.00155030 | validation error =    4\n",
      "    Epoch 1700 : loss = 0.00058254 | validation error =    4\n",
      "    Epoch 1800 : loss = 0.00034154 | validation error =    4\n",
      "    Epoch 1900 : loss = 0.00030740 | validation error =    4\n",
      "    Epoch 2000 : loss = 0.00010899 | validation error =    4\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.80896950 | validation error =  252\n",
      "    Epoch  100 : loss = 0.00177212 | validation error =    0\n",
      "    Epoch  200 : loss = 0.00034045 | validation error =    0\n",
      "    Epoch  300 : loss = 0.00016541 | validation error =    0\n",
      "    Epoch  400 : loss = 0.00006276 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00003105 | validation error =    0\n",
      "    Epoch  600 : loss = 0.00004990 | validation error =    0\n",
      "    Epoch  700 : loss = 0.95458124 | validation error =   29\n",
      "    Epoch  800 : loss = 0.05255884 | validation error =   10\n",
      "    Epoch  900 : loss = 0.00192446 | validation error =    8\n",
      "    Epoch 1000 : loss = 0.00098310 | validation error =    8\n",
      "    Epoch 1100 : loss = 4.38401690 | validation error =  121\n",
      "    Epoch 1200 : loss = 0.00445124 | validation error =    6\n",
      "    Epoch 1300 : loss = 0.00108927 | validation error =    6\n",
      "    Epoch 1400 : loss = 0.00051208 | validation error =    5\n",
      "    Epoch 1500 : loss = 0.00029223 | validation error =    5\n",
      "    Epoch 1600 : loss = 0.00025151 | validation error =    5\n",
      "    Epoch 1700 : loss = 0.00012047 | validation error =    2\n",
      "    Epoch 1800 : loss = 0.18325589 | validation error =    9\n",
      "    Epoch 1900 : loss = 0.00159424 | validation error =    7\n",
      "    Epoch 2000 : loss = 0.00062774 | validation error =    7\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.94950318 | validation error =  231\n",
      "    Epoch  100 : loss = 0.00092951 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00030245 | validation error =    2\n",
      "    Epoch  300 : loss = 0.00012960 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00006142 | validation error =    2\n",
      "    Epoch  500 : loss = 0.00004858 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00002114 | validation error =    2\n",
      "    Epoch  700 : loss = 0.82554658 | validation error =   40\n",
      "    Epoch  800 : loss = 0.29313326 | validation error =   14\n",
      "    Epoch  900 : loss = 0.04939261 | validation error =   13\n",
      "    Epoch 1000 : loss = 0.01232876 | validation error =    6\n",
      "    Epoch 1100 : loss = 0.00184943 | validation error =    9\n",
      "    Epoch 1200 : loss = 0.00066298 | validation error =    9\n",
      "    Epoch 1300 : loss = 0.02926951 | validation error =    7\n",
      "    Epoch 1400 : loss = 0.03398357 | validation error =    8\n",
      "    Epoch 1500 : loss = 0.00217894 | validation error =    7\n",
      "    Epoch 1600 : loss = 0.39604833 | validation error =   23\n",
      "    Epoch 1700 : loss = 0.00478285 | validation error =    9\n",
      "    Epoch 1800 : loss = 0.00076870 | validation error =    7\n",
      "    Epoch 1900 : loss = 0.00038309 | validation error =    6\n",
      "    Epoch 2000 : loss = 0.21782461 | validation error =   17\n",
      "Done.\n",
      "\n",
      "MODEL CNN_batchnorm\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.72504681 | validation error =  336\n",
      "    Epoch  100 : loss = 0.00517967 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00125230 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00048954 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00022857 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00011633 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00006220 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00003425 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00001923 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00001098 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00000635 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00000371 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00000218 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00000129 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00000077 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00000046 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00000027 | validation error =    1\n",
      "    Epoch 1700 : loss = 0.00000016 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00000010 | validation error =    1\n",
      "    Epoch 1900 : loss = 0.00000006 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.00000004 | validation error =    1\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.55879968 | validation error =  317\n",
      "    Epoch  100 : loss = 0.00104492 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00025567 | validation error =    0\n",
      "    Epoch  300 : loss = 0.00010260 | validation error =    0\n",
      "    Epoch  400 : loss = 0.00004962 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00002617 | validation error =    0\n",
      "    Epoch  600 : loss = 0.00001445 | validation error =    0\n",
      "    Epoch  700 : loss = 0.00000822 | validation error =    0\n",
      "    Epoch  800 : loss = 0.00000477 | validation error =    0\n",
      "    Epoch  900 : loss = 0.00000283 | validation error =    0\n",
      "    Epoch 1000 : loss = 0.02218291 | validation error =    5\n",
      "    Epoch 1100 : loss = 0.00135709 | validation error =    3\n",
      "    Epoch 1200 : loss = 0.00053546 | validation error =    3\n",
      "    Epoch 1300 : loss = 0.00025986 | validation error =    3\n",
      "    Epoch 1400 : loss = 0.00013721 | validation error =    2\n",
      "    Epoch 1500 : loss = 0.00007574 | validation error =    2\n",
      "    Epoch 1600 : loss = 0.00004279 | validation error =    2\n",
      "    Epoch 1700 : loss = 0.00002449 | validation error =    2\n",
      "    Epoch 1800 : loss = 0.00001413 | validation error =    2\n",
      "    Epoch 1900 : loss = 0.00000818 | validation error =    2\n",
      "    Epoch 2000 : loss = 0.00000476 | validation error =    2\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.70034105 | validation error =  308\n",
      "    Epoch  100 : loss = 0.00056297 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00013617 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00005348 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00002509 | validation error =    1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch  500 : loss = 0.00001286 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00000692 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00000383 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00000216 | validation error =    1\n",
      "    Epoch  900 : loss = 0.00000124 | validation error =    1\n",
      "    Epoch 1000 : loss = 0.00000071 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00000041 | validation error =    1\n",
      "    Epoch 1200 : loss = 0.00000024 | validation error =    1\n",
      "    Epoch 1300 : loss = 0.00000014 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00000008 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00000005 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00000003 | validation error =    1\n",
      "    Epoch 1700 : loss = 0.00000002 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00000001 | validation error =    1\n",
      "    Epoch 1900 : loss = 0.00000001 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.00000000 | validation error =    1\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.31227124 | validation error =  309\n",
      "    Epoch  100 : loss = 0.00032947 | validation error =    0\n",
      "    Epoch  200 : loss = 0.00008490 | validation error =    0\n",
      "    Epoch  300 : loss = 0.00003407 | validation error =    0\n",
      "    Epoch  400 : loss = 0.00001623 | validation error =    0\n",
      "    Epoch  500 : loss = 0.00000842 | validation error =    0\n",
      "    Epoch  600 : loss = 0.00000458 | validation error =    0\n",
      "    Epoch  700 : loss = 0.00000256 | validation error =    0\n",
      "    Epoch  800 : loss = 0.00000145 | validation error =    0\n",
      "    Epoch  900 : loss = 0.00000083 | validation error =    0\n",
      "    Epoch 1000 : loss = 0.00000048 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00000028 | validation error =    0\n",
      "    Epoch 1200 : loss = 0.00000016 | validation error =    0\n",
      "    Epoch 1300 : loss = 0.00000009 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00000006 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00000003 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00000002 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00000000 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00000000 | validation error =    0\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.61097866 | validation error =  227\n",
      "    Epoch  100 : loss = 0.00017511 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00005384 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00002351 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00001175 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00000627 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00000347 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00000196 | validation error =    0\n",
      "    Epoch  800 : loss = 0.00000112 | validation error =    0\n",
      "    Epoch  900 : loss = 0.00000064 | validation error =    0\n",
      "    Epoch 1000 : loss = 0.00000037 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00000022 | validation error =    0\n",
      "    Epoch 1200 : loss = 0.00000013 | validation error =    0\n",
      "    Epoch 1300 : loss = 0.00000007 | validation error =    0\n",
      "    Epoch 1400 : loss = 0.00000004 | validation error =    0\n",
      "    Epoch 1500 : loss = 0.00000003 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00000001 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00000000 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00000000 | validation error =    0\n",
      "Done.\n",
      "\n",
      "MODEL CNN_both\n",
      "==================\n",
      "  Learning rate 0.001 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.27625793 | validation error =  317\n",
      "    Epoch  100 : loss = 0.02442688 | validation error =    3\n",
      "    Epoch  200 : loss = 0.00593411 | validation error =    2\n",
      "    Epoch  300 : loss = 0.00293848 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00131623 | validation error =    3\n",
      "    Epoch  500 : loss = 0.00098979 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00041725 | validation error =    3\n",
      "    Epoch  700 : loss = 0.00034530 | validation error =    3\n",
      "    Epoch  800 : loss = 0.00013392 | validation error =    3\n",
      "    Epoch  900 : loss = 0.01277712 | validation error =    6\n",
      "    Epoch 1000 : loss = 0.00387858 | validation error =    6\n",
      "    Epoch 1100 : loss = 0.00190383 | validation error =    3\n",
      "    Epoch 1200 : loss = 0.00107415 | validation error =    3\n",
      "    Epoch 1300 : loss = 0.00065126 | validation error =    3\n",
      "    Epoch 1400 : loss = 0.00037357 | validation error =    4\n",
      "    Epoch 1500 : loss = 0.00024560 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00013771 | validation error =    2\n",
      "    Epoch 1700 : loss = 0.00010416 | validation error =    1\n",
      "    Epoch 1800 : loss = 0.00007131 | validation error =    2\n",
      "    Epoch 1900 : loss = 0.00003802 | validation error =    1\n",
      "    Epoch 2000 : loss = 0.01745078 | validation error =    4\n",
      "  Learning rate 0.0025 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 7.03842735 | validation error =  343\n",
      "    Epoch  100 : loss = 0.00462539 | validation error =    3\n",
      "    Epoch  200 : loss = 0.00177243 | validation error =    3\n",
      "    Epoch  300 : loss = 0.00081233 | validation error =    3\n",
      "    Epoch  400 : loss = 0.00034852 | validation error =    3\n",
      "    Epoch  500 : loss = 0.00025678 | validation error =    3\n",
      "    Epoch  600 : loss = 0.00018456 | validation error =    3\n",
      "    Epoch  700 : loss = 0.00006688 | validation error =    3\n",
      "    Epoch  800 : loss = 0.02062178 | validation error =    4\n",
      "    Epoch  900 : loss = 0.00316743 | validation error =    3\n",
      "    Epoch 1000 : loss = 0.00133892 | validation error =    2\n",
      "    Epoch 1100 : loss = 0.00064718 | validation error =    2\n",
      "    Epoch 1200 : loss = 0.01914472 | validation error =    5\n",
      "    Epoch 1300 : loss = 0.00325690 | validation error =    3\n",
      "    Epoch 1400 : loss = 0.00113550 | validation error =    3\n",
      "    Epoch 1500 : loss = 0.00069613 | validation error =    3\n",
      "    Epoch 1600 : loss = 0.00079473 | validation error =    3\n",
      "    Epoch 1700 : loss = 0.00044354 | validation error =    3\n",
      "    Epoch 1800 : loss = 0.00012528 | validation error =    3\n",
      "    Epoch 1900 : loss = 0.00019190 | validation error =    3\n",
      "    Epoch 2000 : loss = 0.00816154 | validation error =    5\n",
      "  Learning rate 0.005 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.95801741 | validation error =  317\n",
      "    Epoch  100 : loss = 0.00180458 | validation error =    0\n",
      "    Epoch  200 : loss = 0.00063081 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00020430 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00016687 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00008532 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00007893 | validation error =    2\n",
      "    Epoch  700 : loss = 0.00002676 | validation error =    2\n",
      "    Epoch  800 : loss = 0.00001930 | validation error =    0\n",
      "    Epoch  900 : loss = 0.00001028 | validation error =    2\n",
      "    Epoch 1000 : loss = 1.82445224 | validation error =   41\n",
      "    Epoch 1100 : loss = 0.00739806 | validation error =    2\n",
      "    Epoch 1200 : loss = 0.00235675 | validation error =    2\n",
      "    Epoch 1300 : loss = 0.00112241 | validation error =    3\n",
      "    Epoch 1400 : loss = 0.00050169 | validation error =    2\n",
      "    Epoch 1500 : loss = 0.00270669 | validation error =    0\n",
      "    Epoch 1600 : loss = 0.00156578 | validation error =    0\n",
      "    Epoch 1700 : loss = 0.00038983 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00035217 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00011750 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00015405 | validation error =    0\n",
      "  Learning rate 0.0075 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.99512851 | validation error =  265\n",
      "    Epoch  100 : loss = 0.00116129 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00574058 | validation error =    2\n",
      "    Epoch  300 : loss = 0.00101402 | validation error =    2\n",
      "    Epoch  400 : loss = 0.00053027 | validation error =    2\n",
      "    Epoch  500 : loss = 0.00015543 | validation error =    2\n",
      "    Epoch  600 : loss = 0.00009420 | validation error =    2\n",
      "    Epoch  700 : loss = 0.00007571 | validation error =    2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch  800 : loss = 0.00001973 | validation error =    2\n",
      "    Epoch  900 : loss = 0.00002339 | validation error =    2\n",
      "    Epoch 1000 : loss = 0.00007515 | validation error =    1\n",
      "    Epoch 1100 : loss = 0.00780443 | validation error =    2\n",
      "    Epoch 1200 : loss = 0.00321243 | validation error =    4\n",
      "    Epoch 1300 : loss = 0.00094258 | validation error =    3\n",
      "    Epoch 1400 : loss = 2.78687574 | validation error =   68\n",
      "    Epoch 1500 : loss = 0.00386805 | validation error =    3\n",
      "    Epoch 1600 : loss = 0.00218911 | validation error =    4\n",
      "    Epoch 1700 : loss = 0.00031840 | validation error =    2\n",
      "    Epoch 1800 : loss = 0.00025525 | validation error =    2\n",
      "    Epoch 1900 : loss = 0.00024211 | validation error =    3\n",
      "    Epoch 2000 : loss = 0.00002352 | validation error =    1\n",
      "  Learning rate 0.01 :\n",
      "-----------------------\n",
      "    Epoch    1 : loss = 6.68809742 | validation error =  318\n",
      "    Epoch  100 : loss = 0.00085660 | validation error =    1\n",
      "    Epoch  200 : loss = 0.00031577 | validation error =    1\n",
      "    Epoch  300 : loss = 0.00016357 | validation error =    1\n",
      "    Epoch  400 : loss = 0.00007835 | validation error =    1\n",
      "    Epoch  500 : loss = 0.00004153 | validation error =    1\n",
      "    Epoch  600 : loss = 0.00003208 | validation error =    1\n",
      "    Epoch  700 : loss = 0.00005756 | validation error =    1\n",
      "    Epoch  800 : loss = 0.00000409 | validation error =    1\n",
      "    Epoch  900 : loss = 0.53969647 | validation error =   12\n",
      "    Epoch 1000 : loss = 0.01936737 | validation error =    0\n",
      "    Epoch 1100 : loss = 0.00403570 | validation error =    0\n",
      "    Epoch 1200 : loss = 0.00334239 | validation error =    0\n",
      "    Epoch 1300 : loss = 0.00166835 | validation error =    1\n",
      "    Epoch 1400 : loss = 0.00044903 | validation error =    1\n",
      "    Epoch 1500 : loss = 0.00026756 | validation error =    1\n",
      "    Epoch 1600 : loss = 0.00045364 | validation error =    1\n",
      "    Epoch 1700 : loss = 0.00874686 | validation error =    0\n",
      "    Epoch 1800 : loss = 0.00246253 | validation error =    0\n",
      "    Epoch 1900 : loss = 0.00042066 | validation error =    0\n",
      "    Epoch 2000 : loss = 0.00013341 | validation error =    0\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    all_results, best_epoch, best_lr, best_error = find_best_params(m, Variable(train_input), Variable(train_target), Variable(validation_input), Variable(validation_target), learning_rates, nb_epochs_total, epoch_step, mini_batch_size)\n",
    "    print(\"\")\n",
    "    json_res = {\"model\":m().__class__.__name__,   \"learning_rates\":learning_rates, \"nb_epochs_total\":nb_epochs_total, \"epoch_step\":epoch_step, \"mini_batch_size\":mini_batch_size, \"best_epoch\":best_epoch, \"best_lr\":best_lr, \"best_error\":best_error, \"results\":all_results}\n",
    "    json.dump(json_res,open('results/adam/'+json_res[\"model\"]+'.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct each one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_1D\n",
      "For 960 epochs, with a learning rate of 0.0025\n",
      "23.1\n",
      "==========\n",
      "CNN_dropout\n",
      "For 1220 epochs, with a learning rate of 0.001\n",
      "21.3\n",
      "==========\n",
      "CNN_batchnorm\n",
      "For 170 epochs, with a learning rate of 0.0025\n",
      "23.7\n",
      "==========\n",
      "CNN_both\n",
      "For 100 epochs, with a learning rate of 0.005\n",
      "27.0\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "error_rates = []\n",
    "for m in models:\n",
    "    model = m()\n",
    "    json_res = json.load(open('results/adam/'+model.__class__.__name__+'.json','r'))\n",
    "    print(json_res[\"model\"])\n",
    "    print(\"For\", json_res['best_epoch'], \"epochs, with a learning rate of\", json_res['best_lr'])\n",
    "    train_model(model, Variable(train_input), Variable(train_target), json_res['mini_batch_size'], nb_epochs=json_res['best_epoch'], learning_rate=json_res['best_lr'], verbose=False)\n",
    "    test_error = compute_nb_errors(model, Variable(test_input), Variable(test_target))\n",
    "    print(100*(test_error/test_input.size(0)))\n",
    "    error_rates.append(100*(test_error/test_input.size(0)))\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAJzCAYAAAASpuXAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKzg/wNAIMUiMJcGygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3ddac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "colormap = 'Blues'\n",
    "normal_xticks = normal_results['nb_epochs']\n",
    "normal_yticks = normal_results['learning_rates']\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(np.array(normal_results['results'][0]).T, cmap=colormap)\n",
    "plt.xlabel('Nb of epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.xticks(range(len(normal_xticks)), normal_xticks)\n",
    "plt.yticks(range(len(normal_yticks)), normal_yticks)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('Without dropout layer and batch size 20')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(np.array(normal_results['results'][1]).T, cmap=colormap)\n",
    "plt.xlabel('Nb of epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.xticks(range(len(normal_xticks)), normal_xticks)\n",
    "plt.yticks(range(len(normal_yticks)), normal_yticks)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('Without dropout layer and batch size 40')\n",
    "\n",
    "dropout_xticks = dropout_results['nb_epochs']\n",
    "dropout_yticks = dropout_results['learning_rates']\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(dropout_results['results'][0], cmap=colormap)\n",
    "plt.xlabel('Nb of epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.xticks(range(len(dropout_xticks)), dropout_xticks)\n",
    "plt.yticks(range(len(dropout_yticks)), dropout_yticks)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('With dropout layer and batch size 20')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(dropout_results['results'][1], cmap=colormap)\n",
    "plt.xlabel('Nb of epochs')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.xticks(range(len(dropout_xticks)), dropout_xticks)\n",
    "plt.yticks(range(len(dropout_yticks)), dropout_yticks)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('With dropout layer and batch size 40')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results_1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
