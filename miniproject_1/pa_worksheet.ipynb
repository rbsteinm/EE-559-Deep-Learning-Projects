{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input , train_target = bci.load(root = './data_bci')\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://documents.epfl.ch/users/f/fl/fleuret/www/data/bci/sp1s_aa_train_1000Hz.txt\n",
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "Downloading https://documents.epfl.ch/users/f/fl/fleuret/www/data/bci/sp1s_aa_test_1000Hz.txt\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input , train_target = bci.load(root = './data_bci', one_khz = True)\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False, one_khz = True)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  41.8000   44.8000   47.1000  ...    69.8000   72.6000   76.1000\n",
       " -10.3000   -5.9000   -3.3000  ...    12.6000   24.0000   26.5000\n",
       "  38.1000   25.2000   46.0000  ...    45.1000   74.1000   64.8000\n",
       "             ...                â‹±                ...             \n",
       "   7.9000   11.2000   14.3000  ...    32.7000   43.4000   45.5000\n",
       "  19.2000   33.6000   33.8000  ...    46.7000   53.7000   43.4000\n",
       "  -0.4000   12.7000   12.0000  ...    30.7000   40.6000   33.1000\n",
       "[torch.FloatTensor of size 28x50]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.LongTensor of size 316]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg.fit(train_input.view(train_input.size(0),-1),train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = logistic_reg.predict(test_input.view(test_input.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*(1-(torch.LongTensor(pred) - test_target).abs().sum()/test_input.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden=64):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"======\")\n",
    "        print(x.size())\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        print(x.size())\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        print(x.size())\n",
    "        x = self.fc2(x)\n",
    "        print(x.size())\n",
    "        print(\"======\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cool_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "torch.Size([316, 1, 28, 50])\n",
      "torch.Size([316, 32, 8, 15])\n",
      "torch.Size([316, 64, 2, 5])\n",
      "torch.Size([790, 64])\n",
      "torch.Size([790, 2])\n",
      "======\n",
      "torch.Size([790, 2])\n",
      "torch.Size([316])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/THNN/generic/ClassNLLCriterion.c:79",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-670f7ca518f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_cool_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Cours/Deep Learning/DL_projects/miniproject_1/helpers.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target, nb_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 679\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \"\"\"\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/THNN/generic/ClassNLLCriterion.c:79"
     ]
    }
   ],
   "source": [
    "train_model(my_cool_net, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_errors = compute_nb_errors(net, Variable(test_input.view(test_input.size(0),-1)), Variable(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_errors/test_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "                ...                   â‹±                   ...                \n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "        inf         nan         nan  ...          nan         nan         nan\n",
      "[torch.FloatTensor of size 2000x1400]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "     inf\n",
      "     inf\n",
      "     inf\n",
      "    â‹®   \n",
      "     inf\n",
      "     inf\n",
      "     inf\n",
      "[torch.FloatTensor of size 2000]\n",
      "\n",
      "Parameter containing:\n",
      "        inf         inf         inf  ...          inf         inf         inf\n",
      " 7.4822e-04  1.8017e-02  4.9546e-03  ...  -1.0733e-02 -1.6233e-02 -2.1673e-03\n",
      " 9.0141e-03  1.6760e-02 -1.5477e-02  ...   1.0472e-02 -5.0546e-03 -7.6107e-04\n",
      "                ...                   â‹±                   ...                \n",
      " 1.6629e-03  1.9134e-02 -1.0855e-02  ...   1.1089e-02 -2.1560e-02 -1.4515e+05\n",
      "        nan         nan         nan  ...          nan         nan         nan\n",
      "        nan         nan         nan  ...          nan         nan         nan\n",
      "[torch.FloatTensor of size 5000x2000]\n",
      "\n",
      "Parameter containing:\n",
      "        inf\n",
      "-6.7252e-01\n",
      " 3.3973e+15\n",
      "     â‹®     \n",
      "-4.9959e+00\n",
      "        inf\n",
      "        inf\n",
      "[torch.FloatTensor of size 5000]\n",
      "\n",
      "Parameter containing:\n",
      "        nan  1.2458e-02  7.1752e-03  ...  -1.6205e-04         nan         nan\n",
      "        nan -8.9752e-03 -7.9428e-03  ...   4.7856e-03         nan         nan\n",
      "        nan -1.3659e-02  1.1348e-02  ...   1.1194e-02         nan         nan\n",
      "                ...                   â‹±                   ...                \n",
      "        inf  5.6094e+04  2.4978e+32  ...   1.5260e+05         inf         inf\n",
      "        inf  1.4062e+06  6.2325e+33  ...   3.8253e+06         inf         inf\n",
      "        nan  5.9156e-03  1.3203e-02  ...   1.2007e-02         nan         nan\n",
      "[torch.FloatTensor of size 1000x5000]\n",
      "\n",
      "Parameter containing:\n",
      "-4.0087e-03\n",
      " 2.5193e-03\n",
      "-8.0979e-03\n",
      "     â‹®     \n",
      " 2.6289e+16\n",
      " 6.5596e+17\n",
      " 2.9761e-03\n",
      "[torch.FloatTensor of size 1000]\n",
      "\n",
      "Parameter containing:\n",
      "-1.5525e-02 -2.5757e-02 -2.6768e-02  ...          nan         nan -1.6155e-02\n",
      " 1.6219e-03  3.1195e-02  1.5566e-02  ...          nan         nan  1.2701e-02\n",
      "[torch.FloatTensor of size 2x1000]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  3.6271\n",
      "  2.5074\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " nan\n",
       " [torch.FloatTensor of size 100], Variable containing:\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 100])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(net(Variable(test_input.view(test_input.size(0),-1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.6572  0.0148\n",
       "-4.1458  1.6060\n",
       "-3.4840  0.6600\n",
       "-3.8114  0.2711\n",
       "-2.0816 -0.4006\n",
       "-1.6004  0.9984\n",
       "-2.2228 -0.6758\n",
       "-2.2082 -0.5414\n",
       "-2.1721 -0.0312\n",
       "-3.9432  0.9518\n",
       "-3.7670  1.3886\n",
       "-2.7920  1.0095\n",
       "-1.8241  1.2546\n",
       "-2.2338  0.1086\n",
       "-2.8144 -0.1049\n",
       "-1.6607  0.2411\n",
       "-4.0314  0.7664\n",
       "-2.6379  1.1434\n",
       "-2.5038  1.0571\n",
       "-2.2371 -0.2091\n",
       "-2.4405  0.6255\n",
       "-3.3993  0.3146\n",
       "-2.8773  0.0630\n",
       "-7.2798  2.1457\n",
       "-2.5702  1.2132\n",
       "-2.8056  0.0115\n",
       "-3.5939  1.7304\n",
       "-3.0597  0.0963\n",
       "-3.4168  0.0629\n",
       "-2.3354  0.3484\n",
       "-2.8556  0.5807\n",
       "-3.0493  0.7753\n",
       "-2.7777  0.6547\n",
       "-2.1945 -0.6982\n",
       "-3.2607  0.5900\n",
       "-2.9778  0.8725\n",
       "-2.3618  0.0959\n",
       "-2.4101 -0.3257\n",
       "-2.9874  1.2907\n",
       "-3.5630 -0.1187\n",
       "-2.9051  1.1212\n",
       "-3.4610  0.5801\n",
       "-2.8010  0.4318\n",
       "-2.3829  0.2838\n",
       "-2.5511  0.1325\n",
       "-2.0369 -0.3338\n",
       "-3.3242  0.5825\n",
       "-2.2085 -0.6308\n",
       "-4.3520  2.9381\n",
       "-5.0417  2.9876\n",
       "-5.5641  1.3397\n",
       "-2.8681  0.2895\n",
       "-2.7957  1.0283\n",
       "-2.3342 -0.3569\n",
       "-1.6148 -0.5689\n",
       "-4.3562 -0.1665\n",
       "-2.5958  0.8790\n",
       "-3.4593  1.1641\n",
       "-2.2065  2.0716\n",
       "-3.5562  1.0820\n",
       "-2.2726 -0.0875\n",
       "-4.5947  0.9853\n",
       "-2.4093 -0.3176\n",
       "-2.7613  0.4275\n",
       "-3.8538  0.8135\n",
       "-2.8805  1.1710\n",
       "-2.0016 -1.1033\n",
       "-4.4062  1.2783\n",
       "-2.1731 -0.8402\n",
       "-3.3459  0.1586\n",
       "-2.3901  0.4777\n",
       "-2.4692  0.6504\n",
       "-1.4432 -0.4877\n",
       "-2.1838  0.4477\n",
       "-1.5884 -0.5787\n",
       "-3.1899  0.6761\n",
       "-5.1455  0.6899\n",
       "-3.1750  0.5969\n",
       "-3.3072  0.9810\n",
       "-2.2150  0.1511\n",
       "-3.8661  0.6238\n",
       "-2.2144 -0.9794\n",
       "-2.3982  0.5114\n",
       "-3.4951  1.8114\n",
       "-3.6388  0.9923\n",
       "-2.0606 -0.4727\n",
       "-2.2824 -0.1624\n",
       "-2.5775  1.5136\n",
       "-3.8660  0.4157\n",
       "-2.9108  0.1931\n",
       "-4.3012  1.5683\n",
       "-2.5722  0.2092\n",
       "-2.2221  0.1625\n",
       "-2.9055  0.7397\n",
       "-4.2048 -0.1742\n",
       "-1.9792 -0.1585\n",
       "-2.0939 -0.4735\n",
       "-3.0130  0.6250\n",
       "-2.8490  0.5695\n",
       "-1.6762  0.4163\n",
       "[torch.FloatTensor of size 100x2]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(Variable(test_input.view(test_input.size(0),-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
