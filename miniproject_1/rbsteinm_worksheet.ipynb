{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f847ca4ed30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input , train_target = bci.load(root = './data_bci')\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalize mean to 0\n",
    "train_input.sub_(train_input.mean())\n",
    "test_input.sub_(test_input.mean())\n",
    "\n",
    "# normalize variance to 1\n",
    "train_input.div_(train_input.std())\n",
    "test_input.div_(test_input.std())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "X_train = train_input.view(train_input.size(0), -1)\n",
    "X_test = test_input.view(test_input.size(0), -1)\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "lr.fit(X=X_train, y=train_target)\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "preds = torch.FloatTensor(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = discrete_predictions(preds)\n",
    "accuracy = compute_accuracy(test_target, preds)\n",
    "print('Accuracy ' + str(accuracy*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_input , train_target = bci.load(root = './data_bci')\n",
    "test_input , test_target = bci.load(root = './data_bci', train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the number of samples from 316 to 300 so that we can take bigger minibatches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input2 = train_input[0:300]\n",
    "train_target2 = train_target[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden=64):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(640, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"======\")\n",
    "        print(x.size())\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        print(x.size())\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        print(x.size())\n",
    "        x = F.tanh(self.fc1(x.view(-1, 640)))\n",
    "        print(x.size())\n",
    "        #print(\"======\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_cool_net = Net()\n",
    "train_model(my_cool_net, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4, nb_epochs=50, learning_rate=1e-2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_errors = compute_nb_errors(my_cool_net, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_errors/test_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = compute_nb_errors(my_cool_net, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "train_errors / train_input.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search on model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sizes = [0.01, 0.005, 0.0025, 0.001, 0.0005]\n",
    "nb_iters_ = [25, 50, 100, 250, 500]\n",
    "\n",
    "test_errors = []\n",
    "train_errors = []\n",
    "\n",
    "for lr in step_sizes:\n",
    "    test_errs = []\n",
    "    train_errs = []\n",
    "    for nb_iters in nb_iters_:\n",
    "        # reset and train the network\n",
    "        my_net = Net()\n",
    "        train_model(my_net, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), mini_batch_size=4, nb_epochs=nb_iters, learning_rate=lr)\n",
    "        \n",
    "        # compute the number of errors\n",
    "        n_train_errors = compute_nb_errors(my_net, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "        n_test_errors = compute_nb_errors(my_net, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)\n",
    "        \n",
    "        train_error = n_train_errors / train_input.size(0)\n",
    "        test_error = n_test_errors / test_input.size(0)\n",
    "        \n",
    "        test_errs.append(test_error)\n",
    "        train_errs.append(train_error)\n",
    "        \n",
    "        print('step size: ' + str(lr) + ' nb epochs: ' + str(nb_iters) + ' train error: ' + str(train_error) + ' test error: ' + str(test_error))\n",
    "    test_errors.append(test_errs)\n",
    "    train_errors.append(train_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, nb_hidden=64):\n",
    "        super(Net2, self).__init__()\n",
    "        self.inp = nn.Linear(50, 32)\n",
    "        self.lstm = nn.LSTM(32, 32, 2, dropout=0.05)\n",
    "        #self.lstm2 = nn.LSTM(64, 64, 2, dropout=0.05)\n",
    "        self.out = nn.Linear(28*32, 2)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "        x = F.tanh(self.inp(x))\n",
    "        x, hidden = self.lstm(x.squeeze(1), hc)\n",
    "        x = F.tanh(x)\n",
    "        #x, hidden2 = self.lstm2(x.squeeze(1), hidden)\n",
    "        #x = F.tanh(x)\n",
    "        x = F.tanh(self.out(x.view(-1, 28*32)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 55.869204103946686\n",
      "1 55.43167996406555\n",
      "2 55.19314759969711\n",
      "3 55.059707939624786\n",
      "4 54.94787919521332\n",
      "5 54.82654511928558\n",
      "6 54.69320738315582\n",
      "7 54.43547594547272\n",
      "8 54.04499363899231\n",
      "9 53.71025663614273\n",
      "10 53.101887077093124\n",
      "11 52.36088967323303\n",
      "12 51.46517211198807\n",
      "13 50.23881909251213\n",
      "14 48.79900071024895\n",
      "15 47.382527619600296\n",
      "16 46.05978602170944\n",
      "17 44.92688646912575\n",
      "18 43.7837099134922\n",
      "19 42.69750751554966\n",
      "20 41.3571610301733\n",
      "21 39.86741977930069\n",
      "22 38.91183651983738\n",
      "23 38.50012291967869\n",
      "24 37.5086385756731\n",
      "25 36.48665054142475\n",
      "26 35.347092255949974\n",
      "27 35.29541324079037\n",
      "28 33.63038110733032\n",
      "29 33.86552679538727\n",
      "30 32.97670891880989\n",
      "31 32.42755489051342\n",
      "32 31.461542561650276\n",
      "33 30.93731053173542\n",
      "34 29.90556702017784\n",
      "35 28.646388962864876\n",
      "36 28.038339361548424\n",
      "37 26.947852313518524\n",
      "38 26.298431307077408\n",
      "39 24.39644142985344\n",
      "40 23.045839563012123\n",
      "41 22.45906500518322\n",
      "42 21.94350579380989\n",
      "43 21.287144765257835\n",
      "44 20.972183883190155\n",
      "45 20.335538625717163\n",
      "46 19.979054808616638\n",
      "47 18.904467552900314\n",
      "48 17.95518757402897\n",
      "49 17.47801437973976\n",
      "50 18.638119965791702\n",
      "51 17.376751020550728\n",
      "52 16.12909623980522\n",
      "53 16.097040325403214\n",
      "54 15.878831282258034\n",
      "55 15.313069745898247\n",
      "56 14.767369359731674\n",
      "57 14.877980530261993\n",
      "58 14.938950717449188\n",
      "59 17.115545362234116\n",
      "60 16.481018379330635\n",
      "61 16.52860516309738\n",
      "62 14.838695138692856\n",
      "63 14.371331512928009\n",
      "64 21.032292664051056\n",
      "65 17.59600991010666\n",
      "66 17.030445456504822\n",
      "67 14.876956015825272\n",
      "68 14.048092141747475\n",
      "69 13.687373846769333\n",
      "70 14.570785358548164\n",
      "71 13.710605829954147\n",
      "72 13.22987399995327\n",
      "73 13.25343805551529\n",
      "74 13.021984830498695\n",
      "75 13.027563288807869\n",
      "76 13.220579773187637\n",
      "77 14.094271883368492\n",
      "78 13.166975528001785\n",
      "79 13.047414377331734\n",
      "80 13.265153780579567\n",
      "81 13.602380335330963\n",
      "82 12.99307395517826\n",
      "83 14.021504297852516\n",
      "84 13.039111003279686\n",
      "85 12.441812261939049\n",
      "86 12.721549570560455\n",
      "87 12.549391612410545\n",
      "88 12.33929255604744\n",
      "89 12.357880339026451\n",
      "90 12.31421373784542\n",
      "91 12.27910141646862\n",
      "92 12.244786441326141\n",
      "93 12.226233407855034\n",
      "94 12.237380430102348\n",
      "95 12.302244305610657\n",
      "96 12.22102764248848\n",
      "97 12.20407547056675\n",
      "98 12.185590073466301\n",
      "99 12.173598408699036\n",
      "100 12.162960976362228\n",
      "101 12.173857226967812\n",
      "102 12.119414567947388\n",
      "103 12.142013251781464\n",
      "104 12.107401296496391\n",
      "105 12.025698974728584\n",
      "106 11.876293808221817\n",
      "107 11.857351988554\n",
      "108 11.743282809853554\n",
      "109 11.804872900247574\n",
      "110 11.710308238863945\n",
      "111 11.710301533341408\n",
      "112 11.71216756105423\n",
      "113 11.684447646141052\n",
      "114 11.672751009464264\n",
      "115 11.694800779223442\n",
      "116 11.665811225771904\n",
      "117 11.67261554300785\n",
      "118 11.6599702835083\n",
      "119 11.679309472441673\n",
      "120 11.676421225070953\n",
      "121 11.66608552634716\n",
      "122 11.648955151438713\n",
      "123 11.639150381088257\n",
      "124 11.648941233754158\n",
      "125 11.638982027769089\n",
      "126 11.63468024134636\n",
      "127 11.63980595767498\n",
      "128 11.640941888093948\n",
      "129 11.620460644364357\n",
      "130 11.639987468719482\n",
      "131 11.637843251228333\n",
      "132 11.640967637300491\n",
      "133 11.627722129225731\n",
      "134 11.626141980290413\n",
      "135 11.635578706860542\n",
      "136 11.628085300326347\n",
      "137 11.620600670576096\n",
      "138 11.611448466777802\n",
      "139 11.636710867285728\n",
      "140 11.618125021457672\n",
      "141 11.620350748300552\n",
      "142 11.614411726593971\n",
      "143 11.626042813062668\n",
      "144 11.622352346777916\n",
      "145 11.609661251306534\n",
      "146 11.60806605219841\n",
      "147 11.611727476119995\n",
      "148 11.595488965511322\n",
      "149 11.62254647910595\n",
      "150 11.597109839320183\n",
      "151 11.594920545816422\n",
      "152 11.604507520794868\n",
      "153 11.591162741184235\n",
      "154 11.600596576929092\n",
      "155 11.599603950977325\n",
      "156 11.610842660069466\n",
      "157 11.589666649699211\n",
      "158 11.597726434469223\n",
      "159 11.605483576655388\n",
      "160 11.587140962481499\n",
      "161 11.593378499150276\n",
      "162 11.58482813835144\n",
      "163 11.587408304214478\n",
      "164 11.589179411530495\n",
      "165 11.585331112146378\n",
      "166 11.615540757775307\n",
      "167 11.591204762458801\n",
      "168 11.585380494594574\n",
      "169 11.602443605661392\n",
      "170 11.585407555103302\n",
      "171 11.584968224167824\n",
      "172 11.597065016627312\n",
      "173 11.603742018342018\n",
      "174 11.578249111771584\n",
      "175 11.58103133738041\n",
      "176 11.592622846364975\n",
      "177 11.588629096746445\n",
      "178 11.59104372560978\n",
      "179 11.577748015522957\n",
      "180 11.57955116033554\n",
      "181 11.582161098718643\n",
      "182 11.57448410987854\n",
      "183 11.579415917396545\n",
      "184 11.576908886432648\n",
      "185 11.581105694174767\n",
      "186 11.573159649968147\n",
      "187 11.579393178224564\n",
      "188 11.586252003908157\n",
      "189 11.579172477126122\n",
      "190 11.576870381832123\n",
      "191 11.576165974140167\n",
      "192 11.575713783502579\n",
      "193 11.574864476919174\n",
      "194 11.572875559329987\n",
      "195 11.565780594944954\n",
      "196 11.578620433807373\n",
      "197 11.569769129157066\n",
      "198 11.572558179497719\n",
      "199 11.576034501194954\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "model = Net2()\n",
    "train_model(model,\n",
    "            Variable(train_input.view(-1, 1, 28, 50)),\n",
    "            Variable(train_target),\n",
    "            mini_batch_size=4,\n",
    "            nb_epochs=100,\n",
    "            learning_rate=0.1,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6799999999999999"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_errors = compute_nb_errors(model, Variable(test_input.view(-1, 1, 28, 50)), Variable(test_target), 4)\n",
    "1-nb_errors/test_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990506329113924"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors = compute_nb_errors(model, Variable(train_input.view(-1, 1, 28, 50)), Variable(train_target), 4)\n",
    "1 - train_errors / train_input.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try window slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci as bci\n",
    "train_input_big , train_target_big = bci.load(root = './data_bci', one_khz=True)\n",
    "print(str(type(train_input_big)), train_input_big.size()) \n",
    "print(str(type(train_target_big)), train_target_big.size())\n",
    "test_input_big , test_target_big = bci.load(root = './data_bci', train = False, one_khz=True)\n",
    "print(str(type(test_input_big)), test_input_big.size()) \n",
    "print(str(type(test_target_big)), test_target_big.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([316, 28, 500])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_big.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0  ,.,.) = \n",
       "   30.8000   33.1000   37.9000  ...    39.4000   41.3000   45.0000\n",
       "   46.2000   42.9000   37.6000  ...    62.4000   59.3000   55.7000\n",
       "   55.1000   59.7000   67.7000  ...    67.1000   68.4000   73.9000\n",
       "              ...                ⋱                ...             \n",
       "   84.4000   78.2000   67.3000  ...    35.8000   32.3000   23.9000\n",
       "   19.5000   25.3000   37.0000  ...    76.4000   82.6000   88.7000\n",
       "   87.9000   78.9000   67.9000  ...    58.3000   54.3000   45.9000\n",
       "\n",
       "( 1  ,.,.) = \n",
       "   41.7000   47.8000   59.4000  ...    69.9000   71.3000   77.1000\n",
       "   79.1000   72.4000   62.3000  ...    64.1000   62.0000   55.9000\n",
       "    6.0000    9.9000   18.2000  ...    26.5000   28.3000   32.5000\n",
       "              ...                ⋱                ...             \n",
       "   45.0000   44.0000   38.4000  ...    28.0000   24.7000   20.8000\n",
       "   21.1000   26.8000   34.2000  ...    33.6000   34.0000   36.7000\n",
       "   39.7000   40.1000   36.9000  ...    27.7000   22.4000   13.7000\n",
       "\n",
       "( 2  ,.,.) = \n",
       "    7.8000    8.9000   15.1000  ...    33.8000   39.8000   43.7000\n",
       "   43.0000   39.1000   34.6000  ...    40.2000   38.4000   34.4000\n",
       "   31.6000   33.0000   37.3000  ...    20.9000   21.8000   25.3000\n",
       "              ...                ⋱                ...             \n",
       "   53.9000   49.9000   43.6000  ...    86.9000   85.8000   83.8000\n",
       "   83.4000   86.4000   91.6000  ...    92.5000   93.1000   97.1000\n",
       "  100.3000   98.0000   91.5000  ...    67.8000   64.6000   60.3000\n",
       " ... \n",
       "\n",
       "(3157,.,.) = \n",
       "   83.0000   82.9000   84.4000  ...    88.3000   90.4000   92.8000\n",
       "   94.9000   96.1000   95.3000  ...    92.9000   91.9000   89.8000\n",
       "   87.3000   85.5000   86.3000  ...    78.8000   80.2000   83.7000\n",
       "              ...                ⋱                ...             \n",
       "   86.6000   86.1000   85.1000  ...    82.1000   78.8000   76.1000\n",
       "   76.0000   77.7000   78.8000  ...    75.2000   76.4000   78.2000\n",
       "   79.4000   79.3000   76.5000  ...    86.6000   83.3000   80.5000\n",
       "\n",
       "(3158,.,.) = \n",
       "   78.7000   77.3000   77.3000  ...    90.0000   89.8000   89.4000\n",
       "   89.9000   92.1000   93.7000  ...    71.3000   68.9000   67.9000\n",
       "   67.7000   66.5000   66.4000  ...    73.3000   73.6000   74.6000\n",
       "              ...                ⋱                ...             \n",
       "   86.8000   87.2000   84.4000  ...    97.9000   94.8000   93.1000\n",
       "   73.5000   76.1000   78.4000  ...    87.6000   90.4000   92.4000\n",
       "   92.0000   91.0000   89.4000  ...    82.8000   79.0000   75.5000\n",
       "\n",
       "(3159,.,.) = \n",
       "   75.0000   77.0000   79.0000  ...    85.6000   87.2000   89.1000\n",
       "   89.6000   88.7000   85.7000  ...    89.2000   85.2000   81.9000\n",
       "   80.2000   79.0000   79.2000  ...    93.3000   93.1000   92.3000\n",
       "              ...                ⋱                ...             \n",
       "   74.4000   74.1000   72.4000  ...   103.2000  103.2000  101.3000\n",
       "   99.2000   98.0000   99.0000  ...    67.6000   68.7000   72.4000\n",
       "   76.0000   76.8000   73.0000  ...   105.9000  102.7000  102.2000\n",
       "[torch.FloatTensor of size 3160x28x50]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_big.view(3160, 28, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
